{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction  \n",
    "\n",
    "This is a multi-class classification problem, meaning that there are more than two classes to be predicted, in fact there are three flower species. This is an important type of problem on which to practice with neural networks because the three class values require specialized handling."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Import Classes and Functions\n",
    "\n",
    "We can begin by importing all of the classes and functions we will need in this tutorial.\n",
    "\n",
    "This includes both the functionality we require from Keras, but also data loading from pandas as well as data preparation and model evaluation from scikit-learn."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load\n",
    "import pandas as pd \n",
    "import numpy as np "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Train and save model  \n",
    "\n",
    "## 3.1 Load our data  \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv('data/customertrain.csv')\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
       "0  462809    Male           No   22        No     Healthcare              1.0   \n",
       "1  462643  Female          Yes   38       Yes       Engineer              NaN   \n",
       "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
       "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
       "4  462669  Female          Yes   40       Yes  Entertainment              NaN   \n",
       "\n",
       "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0            Low          4.0  Cat_4            D  \n",
       "1        Average          3.0  Cat_4            A  \n",
       "2            Low          1.0  Cat_6            B  \n",
       "3           High          2.0  Cat_6            B  \n",
       "4           High          6.0  Cat_6            A  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8068 entries, 0 to 8067\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               8068 non-null   int64  \n",
      " 1   Gender           8068 non-null   object \n",
      " 2   Ever_Married     7928 non-null   object \n",
      " 3   Age              8068 non-null   int64  \n",
      " 4   Graduated        7990 non-null   object \n",
      " 5   Profession       7944 non-null   object \n",
      " 6   Work_Experience  7239 non-null   float64\n",
      " 7   Spending_Score   8068 non-null   object \n",
      " 8   Family_Size      7733 non-null   float64\n",
      " 9   Var_1            7992 non-null   object \n",
      " 10  Segmentation     8068 non-null   object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 693.5+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that we have 8068 training examples, but we do have some things to sort out:  \n",
    "\n",
    "- We will neeed to deal with all the null values in some of the features and we will auto generate values\n",
    "- Our output variables 'Y' also has nulls, we will remove those rows"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def prepareY(df):\n",
    "    # Drop rows with no Output values\n",
    "    df.dropna(subset=['Var_1'], inplace=True)\n",
    "\n",
    "    # extract Y and drop from dataframe\n",
    "    Y = df[\"Var_1\"]\n",
    "\n",
    "    # encode class values as integers\n",
    "    yencoder = LabelEncoder()\n",
    "    yencoder.fit(Y)\n",
    "    dump(yencoder,\"models/yencoder.joblib\")\n",
    "    # np.save('models/y_classes.npy', yencoder.classes_) # save for later\n",
    "    return yencoder.transform(Y)\n",
    "    # encoded_Y = yencoder.transform(Y)\n",
    "\n",
    "    # # convert integers to one hot encoded)\n",
    "    # return np_utils.to_categorical(encoded_Y), encoded_Y\n",
    "\n",
    "\n",
    "y = prepareY(df)\n",
    "df = df.drop([\"Var_1\"], axis=1)\n",
    "pd.DataFrame(y).head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   0\n",
       "0  3\n",
       "1  3\n",
       "2  5\n",
       "3  5\n",
       "4  5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Prepare our features  \n",
    "\n",
    "## fillmissing  \n",
    "\n",
    "An important part of regression is understanding which features are missing. We can choose to ignore all rows with missing values, or fill them in with either mode, median or mode.  \n",
    "\n",
    "- Mode = most common value\n",
    "- Median = middle value\n",
    "- Mean = average\n",
    "\n",
    "This is a handy function you can call which will fill in the missing features by your desired method. We will choose to fill in values with the average.  \n",
    "\n",
    "## prepareFeatures  \n",
    "\n",
    "We need to do a few things to our features, so we can work with them a little easier.  \n",
    "\n",
    "- Lets convert our string fields to numbers\n",
    "- Call fillmissing to fill in any missing values in our features.  \n",
    "- Use MinMaxScaler to normalise our numbers so thay have mean of zero with a deviation of 1.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def fillmissing(df, feature, method):\n",
    "    \"\"\"Fills in missing values in features so we do not loose the rows\n",
    "\n",
    "      Parameters:\n",
    "      df (DataFrame): The dataframe with features\n",
    "      feature (string): The feature to fill in\n",
    "      method (string): replace the nill with either mode, median or default to mean\n",
    "    \"\"\"  \n",
    "    if method == \"mode\":\n",
    "      df[feature] = df[feature].fillna(df[feature].mode()[0])\n",
    "    elif method == \"median\":\n",
    "      df[feature] = df[feature].fillna(df[feature].median())\n",
    "    else:\n",
    "      df[feature] = df[feature].fillna(df[feature].mean())\n",
    "\n",
    "def prepareFeatures(df):\n",
    "    \"\"\"Prepares feature for ML\n",
    "\n",
    "      Parameters:\n",
    "      df (DataFrame): The dataframe with features\n",
    "\n",
    "      Returns:\n",
    "      X (nparray): a normalised array of all features\n",
    "    \"\"\"  \n",
    "    # Encode string features to numerics\n",
    "    columns = df.select_dtypes(include=['object']).columns\n",
    "    # columns = [\"Gender\",\"Ever_Married\",\"Graduated\",\"Profession\",\"Spending_Score\"]\n",
    "    for feature in columns:\n",
    "        le = LabelEncoder()\n",
    "        df[feature] = le.fit_transform(df[feature])\n",
    "        # np.save('models/'+feature+'_classes.npy', le.classes_) # save for later\n",
    "        dump(le, 'models/'+feature+'.joblib') \n",
    "\n",
    "    # fill in missing features with mean values\n",
    "    features_missing = df.columns[df.isna().any()]\n",
    "    for feature in features_missing:\n",
    "      fillmissing(df, feature= feature, method= \"mean\")    \n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    X = scaler.fit_transform(df)\n",
    "    dump(scaler, \"models/featurescaler.joblib\") \n",
    "    # np.save('models/featurescaler.npy', le.classes_) # save for later\n",
    "    return X, df\n",
    "\n",
    "df = df.drop([\"Segmentation\",\"ID\"], axis=1) # These fields not features we can use\n",
    "X, df = prepareFeatures(df)\n",
    "pd.DataFrame(X).head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     0    1         2    3         4         5    6     7\n",
       "0  1.0 -1.0 -0.887324 -1.0  0.111111 -0.857143  1.0 -0.25\n",
       "1 -1.0  0.0 -0.436620  0.0 -0.555556 -0.622480 -1.0 -0.50\n",
       "2 -1.0  0.0  0.380282  0.0 -0.555556 -0.857143  1.0 -1.00\n",
       "3  1.0  0.0  0.380282  0.0  0.555556 -1.000000  0.0 -0.75\n",
       "4 -1.0  0.0 -0.380282  0.0 -0.333333 -0.622480  0.0  0.25"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.887324</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.436620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.622480</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.380282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.622480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After funning below, you should see 7992 with non-null values and all should be float64."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "pd.DataFrame(X).info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7992 entries, 0 to 7991\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       7992 non-null   float64\n",
      " 1   1       7992 non-null   float64\n",
      " 2   2       7992 non-null   float64\n",
      " 3   3       7992 non-null   float64\n",
      " 4   4       7992 non-null   float64\n",
      " 5   5       7992 non-null   float64\n",
      " 6   6       7992 non-null   float64\n",
      " 7   7       7992 non-null   float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 499.6 KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.3 Split train and test data  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.4 Hot Encoding Y\n",
    "\n",
    "The output variable contains six different string values.\n",
    "\n",
    "When modeling multi-class classification problems using neural networks, it is good practice to reshape the output attribute from a vector that contains values for each class value to be a matrix with a boolean for each class value and whether or not a given instance has that class value or not.\n",
    "\n",
    "This is called `one hot encoding` or creating dummy variables from a categorical variable.\n",
    "\n",
    "For example, in this problem six class values are [1,2,3,4,5,6]. We can turn this into a one-hot encoded binary matrix for each data instance that would look as follows:    \n",
    "  \n",
    "![onehot](./images/y_one_hot.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "yhot = np_utils.to_categorical(y)\n",
    "yhot_train = np_utils.to_categorical(y_train)\n",
    "yhot_test = np_utils.to_categorical(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.5 Define The Neural Network Model\n",
    "\n",
    "There is a KerasClassifier class in Keras that can be used as an Estimator in scikit-learn, the base type of model in the library. The KerasClassifier takes the name of a function as an argument. This function must return the constructed neural network model, ready for training.\n",
    "\n",
    "Below is a function that will create a baseline neural network for the customer classification problem. It creates a simple fully connected network with one hidden layer that contains 8 neurons.\n",
    "\n",
    "The hidden layer uses a rectifier activation function which is a good practice. Because we used a one-hot encoding for our customer dataset, the output layer must create 6 output values, one for each class. The output value with the largest value will be taken as the class predicted by the model.\n",
    "\n",
    "So, now you are asking “What are reasonable numbers to set these to?”  \n",
    "\n",
    "- Input layer = set to the size of the features, but add a bias neuron (ie. 9)\n",
    "- Hidden layers = set to input_layer * 2 (ie. 18)\n",
    "- Output layer = set to the size of the labels of Y. In our case, this is 7 categories\n",
    "\n",
    "The network topology of this simple one-layer neural network can be summarized as:\n",
    "\n",
    "```\n",
    "9 inputs -> [18 hidden nodes] -> 7 outputs\n",
    "```\n",
    "\n",
    "Note that we use a **softmax** activation function in the output layer. This is to ensure the output values are in the range of 0 and 1 and may be used as predicted probabilities.\n",
    "\n",
    "Finally, the network uses the efficient **Adam gradient descent optimization algorithm** with a logarithmic loss function, which is called **categorical_crossentropy** in Keras."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\t# Rectified Linear Unit Activation Function\n",
    "\tmodel.add(Dense(16, input_dim=8, activation='relu'))\n",
    "\tmodel.add(Dense(16, activation = 'relu'))\n",
    "\t# Softmax for multi-class classification\n",
    "\tmodel.add(Dense(7, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now create our KerasClassifier for use in scikit-learn.\n",
    "\n",
    "We can also pass arguments in the construction of the KerasClassifier class that will be passed on to the fit() function internally used to train the neural network. Here, we pass the number of epochs as 200 and batch size as 5 to use when training the model. Debugging is also turned off when training by setting verbose to 0.  \n",
    "\n",
    "Advantages of using a batch size < number of all samples:  \n",
    "\n",
    "- It requires less memory. Since you train the network using fewer samples, the overall training procedure requires less memory. That's especially important if you are not able to fit the whole dataset in your machine's memory.  \n",
    "- Typically networks train faster with mini-batches. That's because we update the weights after each propagation.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# model = baseline_model()\n",
    "cmodel = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=100, verbose=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.6 Evaluate The Model with k-Fold Cross Validation\n",
    "\n",
    "Now, lets evaluate the neural network model on our training data.\n",
    "\n",
    "The scikit-learn evaluates models using various techniques. The gold standard for evaluating machine learning models is **k-fold cross validation**.\n",
    "\n",
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "\n",
    "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.\n",
    "\n",
    "It is a popular method because it is simple to understand and because it generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split.\n",
    "\n",
    "The general procedure is as follows:\n",
    "\n",
    "1. Shuffle the dataset randomly.  \n",
    "2. Split the dataset into k groups  \n",
    "3. For each unique group:  \n",
    "3.1 Take the group as a hold out or test data set  \n",
    "3.2 Take the remaining groups as a training data set  \n",
    "3.3 Fit a model on the training set and evaluate it on the test set  \n",
    "3.4 Retain the evaluation score and discard the model  \n",
    "4. Summarize the skill of the model using the sample of model evaluation scores  \n",
    "\n",
    "Lets define the model evaluation procedure. Here, we set  \n",
    "\n",
    "- The number of folds to be 10 (a good default) \n",
    "- Shuffle the data before partitioning it. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can evaluate our model (estimator) on our dataset (X and hot_y) using a 10-fold cross-validation procedure (kfold).\n",
    "\n",
    "Evaluating the model returns an object that describes the evaluation of the 10 constructed models for each of the splits of the dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "result = cross_val_score(cmodel, X, yhot, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-22 18:21:30.409109: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-22 18:21:30.518411: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline: 66.13% (1.57%)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.7 Compile and evaluate model on test data  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model = baseline_model()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, yhot_train, validation_split=0.33,\n",
    "                    epochs=200, batch_size=100, verbose=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.8 Plot the learning curve  \n",
    "\n",
    "The plots are provided below. The history for the validation dataset is labeled test by convention as it is indeed a test dataset for the model.\n",
    "\n",
    "From the plot of accuracy we can see that the model could probably be trained a little more as the trend for accuracy on both datasets is still rising for the last few epochs. We can also see that the model has not yet over-learned the training dataset, showing comparable skill on both datasets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 392.14375 277.314375\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-08-22T18:23:02.469078</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 277.314375 \nL 392.14375 277.314375 \nL 392.14375 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 239.758125 \nL 384.94375 239.758125 \nL 384.94375 22.318125 \nL 50.14375 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m8b36071eab\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"65.361932\" xlink:href=\"#m8b36071eab\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(62.180682 254.356562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"103.59857\" xlink:href=\"#m8b36071eab\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(97.23607 254.356562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"141.835207\" xlink:href=\"#m8b36071eab\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(135.472707 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"180.071845\" xlink:href=\"#m8b36071eab\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(173.709345 254.356562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"218.308483\" xlink:href=\"#m8b36071eab\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(208.764733 254.356562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"256.54512\" xlink:href=\"#m8b36071eab\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(247.00137 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"294.781758\" xlink:href=\"#m8b36071eab\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(285.238008 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"333.018396\" xlink:href=\"#m8b36071eab\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(323.474646 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"371.255034\" xlink:href=\"#m8b36071eab\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(361.711284 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- epoch -->\n     <g transform=\"translate(202.315625 268.034687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" id=\"DejaVuSans-70\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" id=\"DejaVuSans-6f\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" id=\"DejaVuSans-63\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" id=\"DejaVuSans-68\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-68\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m55190d4ad1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m55190d4ad1\" y=\"214.274532\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.45 -->\n      <g transform=\"translate(20.878125 218.073751)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m55190d4ad1\" y=\"171.635958\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.50 -->\n      <g transform=\"translate(20.878125 175.435176)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m55190d4ad1\" y=\"128.997383\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.55 -->\n      <g transform=\"translate(20.878125 132.796602)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m55190d4ad1\" y=\"86.358809\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.60 -->\n      <g transform=\"translate(20.878125 90.158028)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-36\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m55190d4ad1\" y=\"43.720234\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.65 -->\n      <g transform=\"translate(20.878125 47.519453)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-36\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- accuracy -->\n     <g transform=\"translate(14.798438 153.5975)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" id=\"DejaVuSans-61\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" id=\"DejaVuSans-75\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" id=\"DejaVuSans-79\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"171.240234\" xlink:href=\"#DejaVuSans-75\"/>\n      <use x=\"234.619141\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"275.732422\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"337.011719\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"391.992188\" xlink:href=\"#DejaVuSans-79\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p0a2d00ecf7)\" d=\"M 65.361932 229.874489 \nL 66.891397 50.081674 \nL 68.420863 43.90939 \nL 69.950328 44.108488 \nL 74.538725 44.108488 \nL 77.597656 43.312046 \nL 79.127121 43.112948 \nL 80.656587 41.918311 \nL 82.186052 41.321018 \nL 83.715518 40.922771 \nL 85.244983 40.325478 \nL 86.774449 40.12638 \nL 88.303914 38.931743 \nL 91.362845 40.524576 \nL 92.892311 39.130841 \nL 94.421776 38.135301 \nL 95.951242 37.737106 \nL 97.480708 38.334399 \nL 100.539639 37.538008 \nL 102.069104 36.343371 \nL 103.59857 37.737106 \nL 105.128035 36.144222 \nL 108.186966 36.542468 \nL 109.716432 35.945124 \nL 111.245897 36.940664 \nL 112.775363 36.741566 \nL 114.304828 36.741566 \nL 115.834294 35.945124 \nL 117.363759 38.135301 \nL 118.893225 37.737106 \nL 120.42269 36.144222 \nL 121.952156 37.338859 \nL 123.481621 35.945124 \nL 125.011087 36.144222 \nL 126.540552 35.945124 \nL 128.070018 35.546929 \nL 129.599483 35.746027 \nL 131.128949 35.546929 \nL 132.658414 35.546929 \nL 134.18788 36.542468 \nL 135.717345 35.746027 \nL 137.246811 36.741566 \nL 138.776276 35.347831 \nL 140.305742 36.144222 \nL 141.835207 35.945124 \nL 143.364673 35.945124 \nL 144.894138 36.144222 \nL 146.423604 34.949585 \nL 147.953069 35.546929 \nL 149.482535 35.148733 \nL 151.012 35.347831 \nL 152.541466 35.347831 \nL 154.070931 35.148733 \nL 155.600397 35.347831 \nL 157.129862 35.945124 \nL 158.659328 34.949585 \nL 160.188793 35.746027 \nL 161.718259 35.347831 \nL 163.247724 35.746027 \nL 164.77719 35.746027 \nL 167.836121 34.949585 \nL 169.365586 35.945124 \nL 170.895052 35.945124 \nL 172.424517 34.750487 \nL 173.953983 34.750487 \nL 175.483448 35.148733 \nL 177.012914 35.148733 \nL 178.54238 35.746027 \nL 180.071845 35.746027 \nL 181.601311 35.347831 \nL 183.130776 35.546929 \nL 184.660242 36.542468 \nL 186.189707 35.347831 \nL 187.719173 35.746027 \nL 189.248638 35.746027 \nL 190.778104 33.954096 \nL 192.307569 36.542468 \nL 193.837035 35.945124 \nL 195.3665 36.542468 \nL 196.895966 35.347831 \nL 198.425431 35.546929 \nL 199.954897 34.949585 \nL 201.484362 34.750487 \nL 203.013828 35.546929 \nL 204.543293 34.750487 \nL 206.072759 36.144222 \nL 207.602224 35.148733 \nL 209.13169 34.750487 \nL 210.661155 35.148733 \nL 212.190621 35.746027 \nL 213.720086 34.949585 \nL 215.249552 35.148733 \nL 216.779017 35.148733 \nL 218.308483 34.750487 \nL 219.837948 35.746027 \nL 221.367414 34.949585 \nL 222.896879 35.347831 \nL 224.426345 34.949585 \nL 225.95581 34.949585 \nL 227.485276 35.347831 \nL 229.014741 36.144222 \nL 230.544207 34.750487 \nL 232.073672 35.347831 \nL 233.603138 34.750487 \nL 235.132603 34.949585 \nL 236.662069 35.746027 \nL 238.191534 34.551389 \nL 239.721 34.551389 \nL 241.250465 35.746027 \nL 242.779931 34.949585 \nL 244.309396 34.551389 \nL 245.838862 35.347831 \nL 247.368327 35.347831 \nL 248.897793 35.746027 \nL 250.427258 35.347831 \nL 251.956724 34.551389 \nL 253.486189 35.945124 \nL 255.015655 35.148733 \nL 256.54512 36.343371 \nL 258.074586 35.347831 \nL 261.133517 34.949585 \nL 262.662983 35.148733 \nL 264.192448 34.551389 \nL 265.721914 34.352292 \nL 267.251379 35.546929 \nL 268.780845 34.750487 \nL 270.31031 35.347831 \nL 271.839776 35.148733 \nL 273.369241 36.144222 \nL 274.898707 35.148733 \nL 276.428172 35.546929 \nL 277.957638 36.741566 \nL 279.487103 34.551389 \nL 281.016569 34.949585 \nL 282.546034 36.343371 \nL 284.0755 35.546929 \nL 285.604965 34.551389 \nL 287.134431 35.347831 \nL 288.663896 35.746027 \nL 290.193362 34.352292 \nL 291.722827 35.546929 \nL 293.252293 34.153194 \nL 294.781758 35.945124 \nL 296.311224 36.343371 \nL 297.840689 35.347831 \nL 299.370155 33.954096 \nL 300.89962 35.546929 \nL 302.429086 36.741566 \nL 303.958551 33.954096 \nL 305.488017 34.750487 \nL 307.017482 33.954096 \nL 308.546948 36.144222 \nL 310.076413 34.949585 \nL 311.605879 34.949585 \nL 313.135344 35.148733 \nL 314.66481 35.546929 \nL 316.194275 34.352292 \nL 317.723741 34.949585 \nL 319.253206 35.148733 \nL 320.782672 35.148733 \nL 322.312137 34.949585 \nL 323.841603 35.347831 \nL 325.371068 35.347831 \nL 326.900534 34.949585 \nL 328.429999 33.55585 \nL 329.959465 34.750487 \nL 331.48893 33.954096 \nL 333.018396 34.551389 \nL 334.547861 34.153194 \nL 336.077327 33.55585 \nL 337.606792 36.343371 \nL 339.136258 34.949585 \nL 340.665724 34.551389 \nL 342.195189 33.954096 \nL 343.724655 34.750487 \nL 346.783586 34.352292 \nL 348.313051 34.551389 \nL 349.842517 33.754998 \nL 351.371982 34.750487 \nL 352.901448 35.546929 \nL 354.430913 33.954096 \nL 355.960379 34.949585 \nL 359.01931 34.949585 \nL 360.548775 34.153194 \nL 362.078241 34.551389 \nL 363.607706 34.352292 \nL 365.137172 34.750487 \nL 366.666637 34.551389 \nL 368.196103 35.148733 \nL 369.725568 34.352292 \nL 369.725568 34.352292 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#p0a2d00ecf7)\" d=\"M 65.361932 75.446585 \nL 66.891397 39.880723 \nL 71.479794 39.880723 \nL 73.009259 39.476581 \nL 74.538725 39.476581 \nL 79.127121 37.051624 \nL 82.186052 37.85996 \nL 83.715518 39.072438 \nL 85.244983 37.85996 \nL 86.774449 38.668296 \nL 88.303914 35.030861 \nL 89.83338 36.647481 \nL 91.362845 37.455817 \nL 92.892311 35.030861 \nL 94.421776 34.222525 \nL 95.951242 35.030861 \nL 97.480708 34.626718 \nL 99.010173 35.435003 \nL 102.069104 36.243339 \nL 103.59857 35.839146 \nL 105.128035 35.030861 \nL 106.657501 35.839146 \nL 108.186966 35.435003 \nL 109.716432 34.626718 \nL 111.245897 36.243339 \nL 112.775363 35.030861 \nL 114.304828 33.41424 \nL 115.834294 35.839146 \nL 117.363759 35.030861 \nL 118.893225 33.818382 \nL 120.42269 33.818382 \nL 121.952156 35.030861 \nL 126.540552 35.030861 \nL 128.070018 34.222525 \nL 129.599483 34.626718 \nL 131.128949 34.222525 \nL 132.658414 35.839146 \nL 134.18788 35.030861 \nL 135.717345 33.41424 \nL 140.305742 34.626718 \nL 141.835207 33.41424 \nL 143.364673 33.818382 \nL 144.894138 34.626718 \nL 146.423604 33.010046 \nL 147.953069 33.818382 \nL 149.482535 33.818382 \nL 151.012 34.626718 \nL 152.541466 33.818382 \nL 154.070931 33.41424 \nL 155.600397 34.222525 \nL 157.129862 33.818382 \nL 158.659328 33.818382 \nL 160.188793 33.41424 \nL 161.718259 34.626718 \nL 163.247724 33.41424 \nL 166.306655 35.030861 \nL 167.836121 33.818382 \nL 169.365586 33.41424 \nL 172.424517 33.41424 \nL 173.953983 34.222525 \nL 175.483448 34.222525 \nL 177.012914 33.41424 \nL 178.54238 34.222525 \nL 180.071845 33.818382 \nL 184.660242 33.818382 \nL 186.189707 34.222525 \nL 187.719173 35.030861 \nL 189.248638 33.818382 \nL 192.307569 35.435003 \nL 193.837035 33.818382 \nL 195.3665 33.818382 \nL 196.895966 33.41424 \nL 198.425431 34.222525 \nL 199.954897 33.818382 \nL 201.484362 33.818382 \nL 203.013828 35.030861 \nL 204.543293 35.435003 \nL 206.072759 34.626718 \nL 207.602224 34.626718 \nL 209.13169 33.818382 \nL 210.661155 33.41424 \nL 212.190621 34.222525 \nL 213.720086 33.818382 \nL 215.249552 33.818382 \nL 216.779017 34.222525 \nL 219.837948 34.222525 \nL 221.367414 33.41424 \nL 222.896879 34.222525 \nL 224.426345 33.010046 \nL 225.95581 34.222525 \nL 227.485276 33.41424 \nL 229.014741 35.839146 \nL 230.544207 34.626718 \nL 232.073672 34.626718 \nL 233.603138 34.222525 \nL 235.132603 34.222525 \nL 236.662069 35.030861 \nL 238.191534 35.030861 \nL 239.721 35.839146 \nL 241.250465 34.626718 \nL 242.779931 35.839146 \nL 245.838862 33.41424 \nL 247.368327 33.818382 \nL 248.897793 35.839146 \nL 250.427258 35.435003 \nL 251.956724 36.647481 \nL 253.486189 36.243339 \nL 255.015655 36.647481 \nL 259.604052 34.222525 \nL 261.133517 34.222525 \nL 262.662983 36.647481 \nL 264.192448 35.839146 \nL 265.721914 33.010046 \nL 267.251379 35.435003 \nL 270.31031 35.435003 \nL 271.839776 35.030861 \nL 273.369241 37.051624 \nL 274.898707 37.051624 \nL 276.428172 35.435003 \nL 277.957638 33.010046 \nL 279.487103 36.243339 \nL 281.016569 32.201761 \nL 282.546034 35.435003 \nL 284.0755 36.647481 \nL 285.604965 35.030861 \nL 287.134431 33.818382 \nL 290.193362 36.243339 \nL 291.722827 34.222525 \nL 293.252293 36.647481 \nL 294.781758 36.243339 \nL 296.311224 34.626718 \nL 297.840689 36.647481 \nL 299.370155 36.647481 \nL 300.89962 34.222525 \nL 302.429086 35.839146 \nL 303.958551 33.818382 \nL 305.488017 35.030861 \nL 307.017482 35.435003 \nL 308.546948 33.41424 \nL 310.076413 36.647481 \nL 311.605879 35.030861 \nL 313.135344 37.051624 \nL 314.66481 35.435003 \nL 316.194275 36.243339 \nL 317.723741 35.030861 \nL 319.253206 35.030861 \nL 320.782672 36.243339 \nL 322.312137 34.222525 \nL 323.841603 34.626718 \nL 326.900534 36.243339 \nL 328.429999 36.647481 \nL 329.959465 35.435003 \nL 331.48893 34.626718 \nL 333.018396 34.626718 \nL 334.547861 33.818382 \nL 336.077327 35.839146 \nL 337.606792 36.243339 \nL 339.136258 35.030861 \nL 340.665724 36.243339 \nL 342.195189 35.839146 \nL 343.724655 36.243339 \nL 345.25412 34.222525 \nL 346.783586 35.839146 \nL 348.313051 34.222525 \nL 349.842517 36.647481 \nL 351.371982 35.030861 \nL 352.901448 34.626718 \nL 354.430913 34.626718 \nL 355.960379 35.435003 \nL 359.01931 34.626718 \nL 360.548775 35.435003 \nL 362.078241 35.435003 \nL 363.607706 35.030861 \nL 365.137172 35.435003 \nL 366.666637 36.647481 \nL 368.196103 35.435003 \nL 369.725568 35.435003 \nL 369.725568 35.435003 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 239.758125 \nL 50.14375 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 384.94375 239.758125 \nL 384.94375 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 239.758125 \nL 384.94375 239.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 22.318125 \nL 384.94375 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_17\">\n    <!-- model accuracy -->\n    <g transform=\"translate(169.882188 16.318125)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" id=\"DejaVuSans-6d\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" id=\"DejaVuSans-64\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-6d\"/>\n     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"158.59375\" xlink:href=\"#DejaVuSans-64\"/>\n     <use x=\"222.070312\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"283.59375\" xlink:href=\"#DejaVuSans-6c\"/>\n     <use x=\"311.376953\" xlink:href=\"#DejaVuSans-20\"/>\n     <use x=\"343.164062\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"404.443359\" xlink:href=\"#DejaVuSans-63\"/>\n     <use x=\"459.423828\" xlink:href=\"#DejaVuSans-63\"/>\n     <use x=\"514.404297\" xlink:href=\"#DejaVuSans-75\"/>\n     <use x=\"577.783203\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"618.896484\" xlink:href=\"#DejaVuSans-61\"/>\n     <use x=\"680.175781\" xlink:href=\"#DejaVuSans-63\"/>\n     <use x=\"735.15625\" xlink:href=\"#DejaVuSans-79\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 57.14375 59.674375 \nL 112.41875 59.674375 \nQ 114.41875 59.674375 114.41875 57.674375 \nL 114.41875 29.318125 \nQ 114.41875 27.318125 112.41875 27.318125 \nL 57.14375 27.318125 \nQ 55.14375 27.318125 55.14375 29.318125 \nL 55.14375 57.674375 \nQ 55.14375 59.674375 57.14375 59.674375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 59.14375 35.416562 \nL 79.14375 35.416562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"text_18\">\n     <!-- train -->\n     <g transform=\"translate(87.14375 38.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" id=\"DejaVuSans-74\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" id=\"DejaVuSans-6e\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-6e\"/>\n     </g>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 59.14375 50.094687 \nL 79.14375 50.094687 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_20\"/>\n    <g id=\"text_19\">\n     <!-- test -->\n     <g transform=\"translate(87.14375 53.594687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-74\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p0a2d00ecf7\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 392.14375 277.314375\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-08-22T18:23:02.708837</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 277.314375 \nL 392.14375 277.314375 \nL 392.14375 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 239.758125 \nL 384.94375 239.758125 \nL 384.94375 22.318125 \nL 50.14375 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mf3d80c1b0c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"65.361932\" xlink:href=\"#mf3d80c1b0c\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(62.180682 254.356562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"103.59857\" xlink:href=\"#mf3d80c1b0c\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(97.23607 254.356562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"141.835207\" xlink:href=\"#mf3d80c1b0c\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(135.472707 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"180.071845\" xlink:href=\"#mf3d80c1b0c\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(173.709345 254.356562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"218.308483\" xlink:href=\"#mf3d80c1b0c\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(208.764733 254.356562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"256.54512\" xlink:href=\"#mf3d80c1b0c\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(247.00137 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"294.781758\" xlink:href=\"#mf3d80c1b0c\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(285.238008 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"333.018396\" xlink:href=\"#mf3d80c1b0c\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(323.474646 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"371.255034\" xlink:href=\"#mf3d80c1b0c\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(361.711284 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- epoch -->\n     <g transform=\"translate(202.315625 268.034687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" id=\"DejaVuSans-70\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" id=\"DejaVuSans-6f\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" id=\"DejaVuSans-63\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" id=\"DejaVuSans-68\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-68\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mf68f151f3e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mf68f151f3e\" y=\"227.496927\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.25 -->\n      <g transform=\"translate(20.878125 231.296146)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mf68f151f3e\" y=\"199.390446\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.30 -->\n      <g transform=\"translate(20.878125 203.189664)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mf68f151f3e\" y=\"171.283964\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.35 -->\n      <g transform=\"translate(20.878125 175.083182)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mf68f151f3e\" y=\"143.177482\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.40 -->\n      <g transform=\"translate(20.878125 146.976701)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mf68f151f3e\" y=\"115.071\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.45 -->\n      <g transform=\"translate(20.878125 118.870219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mf68f151f3e\" y=\"86.964518\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.50 -->\n      <g transform=\"translate(20.878125 90.763737)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mf68f151f3e\" y=\"58.858036\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 0.55 -->\n      <g transform=\"translate(20.878125 62.657255)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mf68f151f3e\" y=\"30.751555\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 0.60 -->\n      <g transform=\"translate(20.878125 34.550773)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-36\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- loss -->\n     <g transform=\"translate(14.798438 140.695937)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-73\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#p1c0774c39d)\" d=\"M 65.361932 32.201761 \nL 66.891397 120.634132 \nL 68.420863 188.087497 \nL 69.950328 209.586911 \nL 71.479794 216.056646 \nL 73.009259 219.008031 \nL 74.538725 220.792855 \nL 76.06819 222.057303 \nL 77.597656 223.009681 \nL 79.127121 223.726214 \nL 82.186052 224.598062 \nL 83.715518 224.955365 \nL 89.83338 225.719693 \nL 91.362845 225.781796 \nL 94.421776 226.128561 \nL 103.59857 226.616301 \nL 105.128035 226.78083 \nL 115.834294 227.163681 \nL 117.363759 227.303299 \nL 121.952156 227.375654 \nL 132.658414 227.752181 \nL 172.424517 228.480332 \nL 173.953983 228.341878 \nL 177.012914 228.530163 \nL 195.3665 228.711294 \nL 204.543293 228.857445 \nL 206.072759 228.756493 \nL 210.661155 228.920787 \nL 218.308483 228.9168 \nL 219.837948 229.014293 \nL 221.367414 228.828303 \nL 229.014741 229.045679 \nL 233.603138 229.010699 \nL 236.662069 229.069887 \nL 241.250465 229.086949 \nL 244.309396 229.135155 \nL 277.957638 229.399648 \nL 281.016569 229.339271 \nL 313.135344 229.549276 \nL 314.66481 229.60977 \nL 316.194275 229.501932 \nL 317.723741 229.623951 \nL 323.841603 229.595036 \nL 333.018396 229.682686 \nL 334.547861 229.617669 \nL 339.136258 229.722323 \nL 346.783586 229.606344 \nL 348.313051 229.736245 \nL 349.842517 229.590546 \nL 351.371982 229.790876 \nL 355.960379 229.709809 \nL 357.489844 229.6822 \nL 359.01931 229.773704 \nL 360.548775 229.723663 \nL 362.078241 229.823979 \nL 366.666637 229.743809 \nL 369.725568 229.874489 \nL 369.725568 229.874489 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path clip-path=\"url(#p1c0774c39d)\" d=\"M 65.361932 75.192046 \nL 66.891397 166.138823 \nL 68.420863 205.546478 \nL 69.950328 215.459829 \nL 71.479794 219.220674 \nL 73.009259 221.129401 \nL 74.538725 222.493529 \nL 76.06819 223.477988 \nL 77.597656 224.149305 \nL 79.127121 224.639006 \nL 82.186052 225.221918 \nL 88.303914 225.764825 \nL 92.892311 225.984906 \nL 112.775363 226.526423 \nL 115.834294 226.450583 \nL 118.893225 226.616988 \nL 120.42269 226.480085 \nL 123.481621 226.614944 \nL 129.599483 226.648617 \nL 135.717345 226.696765 \nL 137.246811 226.557281 \nL 138.776276 226.704136 \nL 140.305742 226.611309 \nL 141.835207 226.716801 \nL 146.423604 226.670497 \nL 147.953069 226.816698 \nL 149.482535 226.711692 \nL 152.541466 226.77423 \nL 158.659328 226.717421 \nL 160.188793 226.830552 \nL 163.247724 226.797767 \nL 164.77719 226.896424 \nL 167.836121 226.769773 \nL 178.54238 226.877376 \nL 180.071845 226.702829 \nL 181.601311 226.986152 \nL 183.130776 226.894179 \nL 189.248638 227.023142 \nL 190.778104 226.87555 \nL 198.425431 226.952764 \nL 201.484362 226.920213 \nL 203.013828 226.736854 \nL 204.543293 226.918136 \nL 213.720086 227.005451 \nL 219.837948 227.039376 \nL 221.367414 226.811253 \nL 222.896879 226.985331 \nL 224.426345 226.783276 \nL 225.95581 226.946281 \nL 235.132603 226.995098 \nL 236.662069 227.063483 \nL 241.250465 226.806177 \nL 245.838862 226.925859 \nL 258.074586 227.033529 \nL 259.604052 226.858999 \nL 262.662983 227.039661 \nL 264.192448 226.979334 \nL 265.721914 226.799526 \nL 267.251379 226.982299 \nL 274.898707 227.007897 \nL 277.957638 226.934503 \nL 279.487103 227.042056 \nL 281.016569 226.61476 \nL 282.546034 227.069413 \nL 284.0755 226.959817 \nL 285.604965 227.102165 \nL 287.134431 226.914651 \nL 290.193362 227.063215 \nL 291.722827 226.94293 \nL 294.781758 226.928992 \nL 296.311224 226.855631 \nL 300.89962 227.021501 \nL 302.429086 227.052192 \nL 303.958551 226.880007 \nL 305.488017 226.995617 \nL 308.546948 226.832982 \nL 310.076413 226.960973 \nL 326.900534 227.035874 \nL 329.959465 227.046881 \nL 331.48893 226.926948 \nL 337.606792 227.017212 \nL 343.724655 227.096 \nL 345.25412 226.908654 \nL 348.313051 227.03445 \nL 349.842517 226.994294 \nL 351.371982 226.814386 \nL 354.430913 226.985733 \nL 363.607706 226.897094 \nL 366.666637 226.986856 \nL 369.725568 226.902338 \nL 369.725568 226.902338 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 239.758125 \nL 50.14375 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 384.94375 239.758125 \nL 384.94375 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 239.758125 \nL 384.94375 239.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 22.318125 \nL 384.94375 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_20\">\n    <!-- model loss -->\n    <g transform=\"translate(185.364063 16.318125)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" id=\"DejaVuSans-6d\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" id=\"DejaVuSans-64\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-6d\"/>\n     <use x=\"97.412109\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"158.59375\" xlink:href=\"#DejaVuSans-64\"/>\n     <use x=\"222.070312\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"283.59375\" xlink:href=\"#DejaVuSans-6c\"/>\n     <use x=\"311.376953\" xlink:href=\"#DejaVuSans-20\"/>\n     <use x=\"343.164062\" xlink:href=\"#DejaVuSans-6c\"/>\n     <use x=\"370.947266\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"432.128906\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"484.228516\" xlink:href=\"#DejaVuSans-73\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 57.14375 59.674375 \nL 112.41875 59.674375 \nQ 114.41875 59.674375 114.41875 57.674375 \nL 114.41875 29.318125 \nQ 114.41875 27.318125 112.41875 27.318125 \nL 57.14375 27.318125 \nQ 55.14375 27.318125 55.14375 29.318125 \nL 55.14375 57.674375 \nQ 55.14375 59.674375 57.14375 59.674375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 59.14375 35.416562 \nL 79.14375 35.416562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_21\"/>\n    <g id=\"text_21\">\n     <!-- train -->\n     <g transform=\"translate(87.14375 38.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" id=\"DejaVuSans-74\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" id=\"DejaVuSans-61\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" id=\"DejaVuSans-6e\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-6e\"/>\n     </g>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 59.14375 50.094687 \nL 79.14375 50.094687 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_23\"/>\n    <g id=\"text_22\">\n     <!-- test -->\n     <g transform=\"translate(87.14375 53.594687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-74\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p1c0774c39d\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test, yhot_test)\n",
    "print('Accuracy from evaluate: %.2f' % (accuracy*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "50/50 [==============================] - 0s 780us/step - loss: 0.2447 - accuracy: 0.6836\n",
      "Accuracy from evaluate: 68.36\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "predict_x = model.predict(X_test)\n",
    "pred = np.argmax(predict_x, axis=1)\n",
    "print(f'Prediction Accuracy: {(pred == y_test).mean() * 100:f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction Accuracy: 68.355222\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.9 Save the model  \n",
    "\n",
    "The model is then converted to JSON format and written to model.json in the local directory. The network weights are written to model.h5 in the local directory.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"models/customermodel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 Reload models from disk and predict  \n",
    "\n",
    "## 2.1 Look at our files\n",
    "\n",
    "The model and weight data is loaded from the saved files and a new model is created. It is important to compile the loaded model before it is used. This is so that predictions made using the model can use the appropriate efficient computation from the Keras backend.\n",
    "\n",
    "The model is evaluated in the same way printing the same evaluation score.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "ls -l models"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total 128\n",
      "-rw-r--r--  1 shaunenslin  staff   515 Aug 22 18:21 Ever_Married.joblib\n",
      "-rw-r--r--  1 shaunenslin  staff   310 Aug 22 17:57 Ever_Married_classes.npy\n",
      "-rw-r--r--  1 shaunenslin  staff   511 Aug 22 18:21 Gender.joblib\n",
      "-rw-r--r--  1 shaunenslin  staff   306 Aug 22 17:57 Gender_classes.npy\n",
      "-rw-r--r--  1 shaunenslin  staff   515 Aug 22 18:21 Graduated.joblib\n",
      "-rw-r--r--  1 shaunenslin  staff   310 Aug 22 17:57 Graduated_classes.npy\n",
      "-rw-r--r--  1 shaunenslin  staff   635 Aug 22 18:21 Profession.joblib\n",
      "-rw-r--r--  1 shaunenslin  staff   430 Aug 22 17:57 Profession_classes.npy\n",
      "-rw-r--r--  1 shaunenslin  staff   522 Aug 22 18:21 Spending_Score.joblib\n",
      "-rw-r--r--  1 shaunenslin  staff   317 Aug 22 17:57 Spending_Score_classes.npy\n",
      "-rw-r--r--  1 shaunenslin  staff  1591 Aug 22 18:23 customermodel.json\n",
      "-rw-r--r--  1 shaunenslin  staff   896 Aug 22 18:21 featurescaler.joblib\n",
      "-rw-r--r--  1 shaunenslin  staff   317 Aug 22 17:14 featurescaler.npy\n",
      "-rw-r--r--  1 shaunenslin  staff   896 Aug 22 17:57 featurescaler.save\n",
      "-rw-r--r--  1 shaunenslin  staff   366 Aug 22 17:49 y_classes.npy\n",
      "-rw-r--r--  1 shaunenslin  staff   571 Aug 22 18:21 yencoder.joblib\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Reload the model  \n",
    "\n",
    "We will reload our data, simulating the vent where we maay be wanting to run a prediction a day or two later."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('modelcustomer.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "# loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4 Reload data  \n",
    "\n",
    "Reload our training data, but take a 10% random sample  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "df = pd.read_csv('data/customertrain.csv')\n",
    "df = df.sample(frac=0.10)\n",
    "df.dropna(inplace=True)\n",
    "df = df.drop([\"Segmentation\",\"ID\"], axis=1) # These fields not features we can use\n",
    "df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 660 entries, 806 to 4067\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Gender           660 non-null    object \n",
      " 1   Ever_Married     660 non-null    object \n",
      " 2   Age              660 non-null    int64  \n",
      " 3   Graduated        660 non-null    object \n",
      " 4   Profession       660 non-null    object \n",
      " 5   Work_Experience  660 non-null    float64\n",
      " 6   Spending_Score   660 non-null    object \n",
      " 7   Family_Size      660 non-null    float64\n",
      " 8   Var_1            660 non-null    object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 51.6+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Gender Ever_Married  Age Graduated Profession  Work_Experience  \\\n",
       "5505    Male          Yes   58       Yes     Doctor              1.0   \n",
       "2527    Male          Yes   35       Yes     Artist              0.0   \n",
       "7638  Female          Yes   86       Yes     Lawyer              0.0   \n",
       "1330  Female          Yes   88       Yes     Lawyer              1.0   \n",
       "2133  Female          Yes   72       Yes     Artist              3.0   \n",
       "\n",
       "     Spending_Score  Family_Size  Var_1  \n",
       "5505           High          2.0  Cat_6  \n",
       "2527        Average          2.0  Cat_6  \n",
       "7638           High          2.0  Cat_6  \n",
       "1330           High          2.0  Cat_6  \n",
       "2133        Average          3.0  Cat_6  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>58</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>35</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Artist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638</th>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>86</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>88</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>72</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Artist</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, when we realod Y, we first want to load our original encoder. Naturally, we cannot have new categories, else we will get an error at this point."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def prepareYreload(df):\n",
    "    # yencoder = LabelEncoder()\n",
    "    # yencoder.classes_ = np.load('models/y_classes.npy', allow_pickle=True) # reload saved class from training\n",
    "    yencoder = load(\"models/yencoder.joblib\")\n",
    "    return yencoder.transform(df[\"Var_1\"])\n",
    "\n",
    "y = prepareYreload(df)\n",
    "df = df.drop([\"Var_1\"], axis=1)\n",
    "pd.DataFrame(y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     0\n",
       "0    5\n",
       "1    5\n",
       "2    5\n",
       "3    2\n",
       "4    5\n",
       "..  ..\n",
       "655  5\n",
       "656  1\n",
       "657  5\n",
       "658  5\n",
       "659  1\n",
       "\n",
       "[660 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def prepareFeaturesReload(df):\n",
    "    \"\"\"Prepares feature for predictions, this time, use classes saved for labelencoder and scaler\n",
    "\n",
    "      Parameters:\n",
    "      df (DataFrame): The dataframe with features\n",
    "\n",
    "      Returns:\n",
    "      X (nparray): a normalised array of all features\n",
    "    \"\"\"  \n",
    "    # Encode string features to numerics\n",
    "    columns = df.select_dtypes(include=['object']).columns\n",
    "    print(columns)\n",
    "    for feature in columns:\n",
    "      print('models/'+feature+'.joblib')\n",
    "      fencoder = load('models/'+feature+'.joblib')\n",
    "      print(fencoder.classes_)\n",
    "      df[feature] = fencoder.fit(df[feature])\n",
    "        # le = LabelEncoder()\n",
    "        # le.classes_ = np.load('models/'+feature+'_classes.npy', allow_pickle=True) # reload saved class from training\n",
    "        # df[feature] = le.fit(df[feature])\n",
    "\n",
    "    # fill in missing features with mean values\n",
    "    features_missing = df.columns[df.isna().any()]\n",
    "    for feature in features_missing:\n",
    "      fillmissing(df, feature= feature, method= \"mean\")    \n",
    "\n",
    "X, df = prepareFeaturesReload(df)\n",
    "pd.DataFrame(X).head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score'], dtype='object')\n",
      "Gender\n",
      "['Female' 'Male']\n",
      "Ever_Married\n",
      "['No' 'Yes' nan]\n",
      "Graduated\n",
      "['No' 'Yes' nan]\n",
      "Profession\n",
      "['Artist' 'Doctor' 'Engineer' 'Entertainment' 'Executive' 'Healthcare'\n",
      " 'Homemaker' 'Lawyer' 'Marketing' nan]\n",
      "Spending_Score\n",
      "['Average' 'High' 'Low']\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z2/6mdbpjn556s1zb_dqy_hj6lr0000gn/T/ipykernel_73443/2016433723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mfillmissing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepareFeaturesReload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict_x = loaded_model.predict(X)\n",
    "pred = np.argmax(predict_x, axis=1)\n",
    "print(f'Prediction Accuracy: {(pred == Y).mean() * 100:f}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Conclusion\n",
    "\n",
    "In this post you discovered how to develop and evaluate a neural network using the Keras Python library for deep learning.\n",
    "You learned:  \n",
    "  \n",
    "- How to load data and make it available to Keras.  \n",
    "- How to prepare multi-class classification data for modeling using one hot encoding.  \n",
    "- How to use Keras neural network models with scikit-learn.  \n",
    "- How to define a neural network using Keras for multi-class classification.  \n",
    "- How to evaluate a Keras neural network model using scikit-learn with k-fold cross validation  \n",
    "\n",
    "Some interesting things to observe:  \n",
    "\n",
    "With batch size of 5, we end up with 66.10% accuracy:  \n",
    "\n",
    "- Without normalising, it takes 3200 seconds for cross_val_score  \n",
    "- With normalising, it takes 1422 seconds for cross_val_score  \n",
    "\n",
    "With batch size of 100, we end up with an accuracy of 66.38%:  \n",
    "\n",
    "- Without normalising, it takes 83 seconds for cross_val_score  \n",
    "- With normalising, it takes 78 seconds for cross_val_score  "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}